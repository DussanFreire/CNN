{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Practica CNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Roqx-d-h88"
      },
      "source": [
        "# Practica de CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP67RnX0-h9B"
      },
      "source": [
        "## Grupo:\n",
        "* Dussan Freire\n",
        "* Jhonny Camacho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpU4dzZA-h9D"
      },
      "source": [
        "### Links Utilizados\n",
        "* __https://keras.io/examples/vision/mnist_convnet/__\n",
        "* __https://victorzhou.com/blog/keras-cnn-tutorial/__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le0MHl_2-h9D"
      },
      "source": [
        "## Librerias usadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auO3GujY-h9E"
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "#import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import timeit\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ancSLALE-h9H"
      },
      "source": [
        "# !pip install tensorflow numpy mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvd5akb-2Js"
      },
      "source": [
        "# Extracci√≥n datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUIERu8B-1WL",
        "outputId": "83b14a07-93c4-4925-a60e-a8260597d6f7"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# The first time you run this might be a bit slow, since the\n",
        "# mnist package has to download and cache the data.\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", train_images.shape)\n",
        "print(\"y_train shape\", train_labels.shape)\n",
        "print(\"X_test shape\", test_images.shape)\n",
        "print(\"y_test shape\", test_labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdH88LcO-h9H"
      },
      "source": [
        "# Experimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj_ISvC6-h9I"
      },
      "source": [
        "## Set Up para los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aN9_GWS-h9K"
      },
      "source": [
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp5TN2Y6-h9N"
      },
      "source": [
        "## Experimento 1\n",
        "Se aumento la cantidad de filtros de 8 a 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHzdbla5-h9N"
      },
      "source": [
        "### Caracteristicas:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjMN_aEv-h9P"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 15\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 3"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5EC6_4q-h9P"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGnLqqNb-h9Q",
        "outputId": "3a11ef2d-b92b-4cb0-ee89-1f17b2381d20"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.3134 - accuracy: 0.9089 - val_loss: 0.1628 - val_accuracy: 0.9541\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1374 - accuracy: 0.9603 - val_loss: 0.1065 - val_accuracy: 0.9695\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0965 - accuracy: 0.9722 - val_loss: 0.0854 - val_accuracy: 0.9741\n",
            "tiempo_de_entrenamiento:  82.67568148299998 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfHIdKM2-h9R"
      },
      "source": [
        "### Guardamos los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XwxFPCC-h9R"
      },
      "source": [
        "model.save_weights('experimeto1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afeGiqWu-h9S"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGHfRZBi-h9T",
        "outputId": "0fe6851c-00c2-403b-ffc4-273a66b5b210"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQyrdk0P-h9U"
      },
      "source": [
        "### Concluision\n",
        "Se mejoro el resultado y pero tomo un poco mas de tiempo entrenar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SXW3fV3-h9U"
      },
      "source": [
        "# Experimento numero 2\n",
        "Se aumento tamano del filro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylKYFlkV-h9V"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFBjO1nI-h9V"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 10\n",
        "pool_size = 2\n",
        "epochs = 3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOR74blK-h9V"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1qexRLl-h9W",
        "outputId": "6b4285f0-903b-4be7-ab3c-b961bd0ada0f"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3130 - accuracy: 0.9102 - val_loss: 0.1570 - val_accuracy: 0.9557\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1360 - accuracy: 0.9606 - val_loss: 0.1007 - val_accuracy: 0.9707\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0965 - accuracy: 0.9716 - val_loss: 0.0797 - val_accuracy: 0.9755\n",
            "tiempo_de_entrenamiento:  82.39007004299998 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WtSBKLY-h9W"
      },
      "source": [
        "### Guardamos los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arz0spTi-h9Y"
      },
      "source": [
        "model.save_weights('experimeto2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bswaS4NJ-h9Y"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy4FvVnM-h9Y",
        "outputId": "a3ccd38d-425a-4f8c-e432-c354b950c5fe"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmCeeJdo-h9Y"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9716 en un tiempo de 82.39 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzM5NCR8-h9Z"
      },
      "source": [
        "# Experimento numero 3\n",
        "Se agrando el pool size de 2 a 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeNNkcO2-h9Z"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6j3Z5UD-h9a"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 4\n",
        "epochs = 3"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5hyrynV-h9a"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAEHYkDH-h9b",
        "outputId": "c38e0c2f-bebb-46f2-986f-5a20a9e263f3"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4046 - accuracy: 0.8854 - val_loss: 0.1764 - val_accuracy: 0.9513\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1534 - accuracy: 0.9550 - val_loss: 0.1189 - val_accuracy: 0.9633\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1172 - accuracy: 0.9649 - val_loss: 0.0957 - val_accuracy: 0.9703\n",
            "tiempo_de_entrenamiento:  46.62441658500006 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KSTG_zm-h9c"
      },
      "source": [
        "### Guardamos los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAXkWZJ--h9c"
      },
      "source": [
        "model.save_weights('experimeto3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjJ6h88g-h9d"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_desB2X-h9d",
        "outputId": "81daccdb-0f11-47e6-ac3b-6742c56d4d99"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGiBZ7J1-h9e"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9649 en un tiempo de 46.62 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE1PrONd-h9e"
      },
      "source": [
        "# Experimento numero 4\n",
        "Se aumentaron las epocas de 3 a 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMQ6NAmo-h9e"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkCGghKH-h9f"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 6"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI5xpBfL-h9f"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIqcgQR4-h9g",
        "outputId": "a60f4096-78de-4499-c70f-3763e17ff931"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3553 - accuracy: 0.8987 - val_loss: 0.2037 - val_accuracy: 0.9404\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1697 - accuracy: 0.9524 - val_loss: 0.1316 - val_accuracy: 0.9612\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1188 - accuracy: 0.9665 - val_loss: 0.1065 - val_accuracy: 0.9694\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0963 - accuracy: 0.9717 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.0843 - val_accuracy: 0.9738\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0745 - accuracy: 0.9777 - val_loss: 0.0830 - val_accuracy: 0.9721\n",
            "tiempo_de_entrenamiento:  142.37407452899993 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U418O2ki-h9g"
      },
      "source": [
        "model.save_weights('experimeto4.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeRzlIVn-h9h"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AF02eR3t-h9h",
        "outputId": "4716d056-f17d-4a63-f58d-7043f484763e"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5].numpy().tolist()) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9]\n",
            "[5, 0, 4, 1, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgKL6wj-h9h"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9777 en un tiempo de 142.37 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63W-kIyz-h9i"
      },
      "source": [
        "# Experimento  5\n",
        "Se aumento una capa de conv2d de 1 a 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuX6CZxF-h9i"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXk3arCe-h9j"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 6"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX5RTiVl-h9k"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O75Ix8BE-h9k",
        "outputId": "3a225c58-254d-443f-eaaf-3c547b053812"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2602 - accuracy: 0.9232 - val_loss: 0.1148 - val_accuracy: 0.9655\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.1001 - accuracy: 0.9706 - val_loss: 0.0894 - val_accuracy: 0.9712\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0790 - accuracy: 0.9759 - val_loss: 0.0766 - val_accuracy: 0.9762\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0669 - accuracy: 0.9791 - val_loss: 0.0715 - val_accuracy: 0.9787\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.0754 - val_accuracy: 0.9763\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0550 - accuracy: 0.9827 - val_loss: 0.0679 - val_accuracy: 0.9791\n",
            "tiempo_de_entrenamiento:  262.3647253710001 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPLIfTg0-h9l"
      },
      "source": [
        "model.save_weights('experimeto5.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-xejJ1F-h9m"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-RFSDh8-h9m",
        "outputId": "0a8e1328-af0e-471c-c193-7f80c2365ff5"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keXcqhB_-h9m"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9827 en un tiempo de 262.36 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIHqEk9h-h9n"
      },
      "source": [
        "# Experimento 6\n",
        "Se aumento una capa \"dropout\", para evitar overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4vrrUtl-h9n"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMByM1Cc-h9n"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 6"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNdj2DCB-h9o"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqkEDQKA-h9o",
        "outputId": "6a358e5b-3c14-479e-c986-d2e6ee6d9e48"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Dropout(0.5),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4357 - accuracy: 0.8701 - val_loss: 0.2162 - val_accuracy: 0.9381\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2632 - accuracy: 0.9206 - val_loss: 0.1668 - val_accuracy: 0.9520\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2288 - accuracy: 0.9315 - val_loss: 0.1463 - val_accuracy: 0.9584\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2140 - accuracy: 0.9350 - val_loss: 0.1333 - val_accuracy: 0.9609\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2002 - accuracy: 0.9390 - val_loss: 0.1222 - val_accuracy: 0.9632\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.1957 - accuracy: 0.9405 - val_loss: 0.1198 - val_accuracy: 0.9648\n",
            "tiempo_de_entrenamiento:  142.38013125399993 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i7WC9jq-h9p"
      },
      "source": [
        "model.save_weights('experimeto6.h5')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Z--OLh-h9p"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXwAcX9n-h9q",
        "outputId": "b0c9f0cf-608d-445d-b0c8-ef99e534730d"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6fbcc66290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNmtDzfe-h9q"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9405 en un tiempo de 142.380 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgO86-mk-h9r"
      },
      "source": [
        "# Experimento  7\n",
        "Se aumento una capa anterior a la capa de salida de 64 unidades de activacion utilizando la funcion relu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aeicPPg-h9r"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqa7UCyB-h9r"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 6"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etIn4vnA-h9r"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwoXkyXD-h9r",
        "outputId": "078709b6-fb08-4a95-df2f-afccba473f43"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2688 - accuracy: 0.9221 - val_loss: 0.1215 - val_accuracy: 0.9625\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1006 - accuracy: 0.9696 - val_loss: 0.0805 - val_accuracy: 0.9741\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0696 - accuracy: 0.9787 - val_loss: 0.0617 - val_accuracy: 0.9798\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0601 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.0656 - val_accuracy: 0.9798\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0683 - val_accuracy: 0.9807\n",
            "tiempo_de_entrenamiento:  142.43029125600015 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp-2zg8u-h9s"
      },
      "source": [
        "model.save_weights('experimeto7.h5')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgkYkh94-h9s"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHx0N71R-h9t",
        "outputId": "3acf5fed-160e-4e27-a6e7-80869391602f"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6fbd755e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzID1seb-h9t"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9895 en un tiempo de 142.430 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvSs4UgC-h9u"
      },
      "source": [
        "# Experimento  8\n",
        "Se jugo con los parametros de la capa de convulucion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chlWU0ei-h9u"
      },
      "source": [
        "### Caracteriscidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GJCHgqx-h9v"
      },
      "source": [
        "# parametros utilizados\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "epochs = 6"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjdA6KUj-h9v"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_dCIXhu-h9v",
        "outputId": "f2d3ad50-43f0-4b6d-bbb1-95494b56a003"
      },
      "source": [
        "# Contruccion del modelo\n",
        "model = Sequential([\n",
        "  Conv2D(\n",
        "    num_filters,\n",
        "    filter_size,\n",
        "    input_shape=(28, 28, 1),\n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "  ),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilacion del modelo\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Crear una closure para poder medir el tiempo\n",
        "def run_experiment1():\n",
        "      model.fit(\n",
        "      train_images,\n",
        "      to_categorical(train_labels),\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_images, to_categorical(test_labels)))\n",
        "\n",
        "# Entrenar el modela\n",
        "execution_time = timeit.timeit(run_experiment1, number=1)\n",
        "\n",
        "print(\"tiempo_de_entrenamiento: \", execution_time,\"[s]\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4804 - accuracy: 0.8723 - val_loss: 0.2253 - val_accuracy: 0.9325\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1967 - accuracy: 0.9428 - val_loss: 0.1645 - val_accuracy: 0.9493\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1607 - accuracy: 0.9520 - val_loss: 0.1421 - val_accuracy: 0.9552\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1420 - accuracy: 0.9576 - val_loss: 0.1267 - val_accuracy: 0.9600\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1309 - accuracy: 0.9601 - val_loss: 0.1280 - val_accuracy: 0.9595\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1210 - accuracy: 0.9636 - val_loss: 0.1136 - val_accuracy: 0.9630\n",
            "tiempo_de_entrenamiento:  82.3931419280002 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5tCo8MC-h9w"
      },
      "source": [
        "model.save_weights('experimeto8.h5')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPEWvh2a-h9w"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j5JC11t-h9w",
        "outputId": "cc81e9b6-e313-4ba9-e44f-9a068c570e94"
      },
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) \n",
        "# print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z7wwjbT-h98"
      },
      "source": [
        "### Concluision\n",
        "La exatitud de la ultima capa 0.9636 en un tiempo de 82.3931 segundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6idkfMJ-h99"
      },
      "source": [
        "# Experimento sacado del link:\n",
        "__https://keras.io/examples/vision/mnist_convnet/__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHZiR3iQ-h99"
      },
      "source": [
        "### Caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddLndEji-h99"
      },
      "source": [
        "# Parametros del modelo \n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "epochs = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBI31ele-h99"
      },
      "source": [
        "### Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OY2IfWO-h9-",
        "outputId": "afbe5516-eb66-4dae-ed93-f680deead5c5"
      },
      "source": [
        "x_train = train_set.train_data\n",
        "y_train = train_set.train_labels\n",
        "x_test  = train_set.test_data\n",
        "y_test = train_set.test_labels\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# Convertir a matrices binarias\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "# Contruccion del modelo\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "60000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNUiE54J-h9_",
        "outputId": "bc840a5f-1792-48d2-fa1a-3219b07a4449"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2oCNINe-h9_"
      },
      "source": [
        "### Modelo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqpwIaLF-h9_",
        "outputId": "13d3d436-e889-468b-ee05-d32e77fa79bb"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "# Evaluacion del modelo entrenado\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.3628 - accuracy: 0.8897 - val_loss: 0.0816 - val_accuracy: 0.9773\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.1138 - accuracy: 0.9650 - val_loss: 0.0594 - val_accuracy: 0.9832\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 37s 89ms/step - loss: 0.0881 - accuracy: 0.9729 - val_loss: 0.0484 - val_accuracy: 0.9860\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 36s 86ms/step - loss: 0.0728 - accuracy: 0.9773 - val_loss: 0.0437 - val_accuracy: 0.9882\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0659 - accuracy: 0.9792 - val_loss: 0.0417 - val_accuracy: 0.9888\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0581 - accuracy: 0.9818 - val_loss: 0.0374 - val_accuracy: 0.9900\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 37s 88ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.0367 - val_accuracy: 0.9897\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.0369 - val_accuracy: 0.9895\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.0345 - val_accuracy: 0.9907\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.0303 - val_accuracy: 0.9908\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 39s 91ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0316 - val_accuracy: 0.9905\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 39s 93ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0299 - val_accuracy: 0.9920\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.0306 - val_accuracy: 0.9925\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 37s 88ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9935\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 37s 88ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0292 - val_accuracy: 0.9917\n",
            "Test loss: 0.01687825657427311\n",
            "Test accuracy: 0.9950500130653381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fowqf9dE-h-A"
      },
      "source": [
        "### Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmEEQqqD-h-A",
        "outputId": "dd850769-137b-44c1-d5ee-83cea61b3067"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.01687825657427311\n",
            "Test accuracy: 0.9950500130653381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}